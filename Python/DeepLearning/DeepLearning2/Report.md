# 深層学習day3
## Section1 再帰ニューラルネットワーク(RNN)の概念
時系列データに対応可能なニューラルネットワーク。  
時系列データとは：時間的なつながりが統計的依存関係があるもの。音声・テキストなど。  
### 実装について
- 時系列を表すために中間層の出力を次の中間層の入力に使う。
- 重みは大きく分けて3か所。入力から中間層、前の中間層からの次の中間層、中間層から出力層。
- t-1の状態からtの状態を求める(再帰的)
### 構文木
単語同士のつながり(特徴量)を学習させ、最後1つの特徴量を学習する。
### BPTT(RNNにおける逆伝搬)
中間層から出力層の重みとバイアスの更新には時間的なつながりを考慮しなくてよい。これらはすでに入力層から中間層への伝達で反映されているので。  
したがって、中間層から出力層への重みとバイアスの更新は総和を計算する必要がない。
## Section2 LSTM
RNNにおいて、時系列によりレイヤーが増えることから勾配消失・勾配爆発問題が起きやすい・(8回で1セットのデータであれば、データを学習するのに8層あるのと同じ。)
### CEC
LNNの記憶部分を担う箇所。勾配問題において、勾配が1であれば影響がない。重みが一律となるため、学習機能がなくなる。
### 入力ゲートと出力ゲート
- 入力ゲート：CECが入力データをどのように記憶させるかを学習する。
- 出力ゲート：CECが記憶でため込んだ内容をどのように出力するかを学習する。
いずれも、時間tの入力に対する重みと時間t-1の出力に対する出力の重みを学習する。
### 忘却ゲート
過去の情報がいらなくなった場合、そのタイミングで情報を忘却する必要がある。
### 確認テスト
忘却ゲートを利用することで、動詞を予測するのに不要な品詞の影響を抑えることができる。
### 覗き穴結合
各ゲートに対して、現在のCECの状態を使用するもの。ただしあまり精度向上は見られなかった。
## Section3 GRU
LSTMではパラメータ数が多く、計算負荷が高い。そのためパラメータを大幅に削減したもの。深層学習では同じような開発の流れをとる。  
CECが完全になくなった形状。ゲートもリセットゲートと更新ゲートのみとなっている。
リセットゲート：隠れ層でどのように状態を保持するかを決める。
更新ゲート：前回の記憶と今回の記憶の使い方を決める。
### 確認テスト
CECの問題点：学習能力がない。記憶しかない。 GRAにはCECが存在しない、
## Section4 双方向RNN
過去の情報だけでなく、未来の情報を加味することで精度を向上させるモデル。  
過去からの入力と現在の入力への層および未来からの入力と現在の入力の層を合わせたもの。  
情報をつぶさずに考慮するには、concateneteを用いる。  
concateneteはaxisの指定で結合方法はが異なる。axis=0は一次元配列。axis=1では同じ要素で二次元の配列を作るイメージ。  
順方向と逆方向の伝搬情報を合わせる場合、t時間の情報をペアとして持つ必要があるので、axis = 1  
## Section5 Seq2Seq
2つのニューラルネットワークを組み合わせたモデル。時系列データから時系列データを生成する。機械翻訳で使用される。  
1つ目のネットワークでは入力で、文脈の意味を保持する。(Encoder)2つ目のネットワークでは文脈の意味から新しい文章を作成する。(Decoder)
### Encode RNN
インプットしたテキストデータを単語等のトークンに区切って渡す。通常記憶させる単語を限定する。3～5万語程度  
1. 単語ごとにIDを振る(Taking)
2. IDに対してone-hotベクトルで表現する。(列数が単語数の行列)
3. IDから、そのトークンを表す分散表現ベクトルに変換(Embedding)(数百程度)。落とし方はディープラーニングで単語の意味を類似性を抽出することで実現する
4. 得られたベクトルを順番にRNNに入力していく(Encoder RNN)

- MLM Masked Language Model：文脈から1単語を隠し、周辺単語から隠した単語を自力で予測させる。教師なし学習。

### Decode RNN
システムがアウトプットデータを単語等のトークンごとに生成する構造。  
処理をEncodeと逆。Embedding表現から近い単語を予想する。
1. Encoder RNNのfinal stateから各tokenの生成確率を出力する。finalstateをDecoderRNNのinitialStateととして、Embeddingを入力する。(DecoderRNN)
2. 生成確率にもとづいて、tokenをランダムに選択。(Sampling)
3. 選ばれたtokenをEmbeddingしてDecoderRNNへの次の入力とする。(Embedding)
4. 上記処理を繰り返し、得られたtokenを文字列に変換する。(Detokenize)

### HRED
seq2seq課題：１問１答しかできない。問いに対して文脈も何もなく、ただ応答が行われ続ける。  
文脈そのものをtokenのようにつながりがあるものとして扱う。RNNの隠れ層をさらにRNNで接続する。  
seq2seq + Context RNN  
Context RNN:Encoderのまとめた各文章の系列をまとめて、これまでの会話コンテキスト全体を表すベクトルに変換する構造。  
HREDの課題：会話の流れの多様性がない。情報量に乏しい答えを返す。相槌など
### VHRED
VAEの潜在変数の概念を導入。HREDよりも表現力の高いモデルを実現する。
### VAE
#### オートエンコーダー(自己符号化器)
教師なし学習の一つ。Encodeで潜在変数zを見つけ出し、Decoderで入力から同一の出力を得るモデル。  
メリット：次元削減を行うことが可能。
#### VAE
潜在変数zを標準正規分布に従うとする。  
オートエンコーダはDecoderが解釈しやすければなんでもよい。(例えば、10個の数字に対してone-hot-vectorの分類を学んでもよい。)  
確率分布を入れることで類似性を表現できるEncoderが学習を行う。  
実際には学習の際に、エンコードの際にノイズを加える。(ドロップアウト？)ノイズがあるため、Decoderの汎用性が上がるもの
## Section6 Word2Vec
単語のEmbeding表現を得るための手法。  
単語同士の意味を保ちながら、ベクトル表現を得る。  
これにより、大量のone-hotvector表現から、現実的な速度とメモリ量で計算可能な学習を可能とした。  
行列のサイズはボキャブラリ×任意の単語ベクトル次元の重み行列で実現可能。
## Section7 Attention Machinism
seq2seqでは長い文章には対応できない。どんな語数でも固定長ベクトルで表現する必要がある。  
そのため、一文の中で大事な単語を見分けて隠れ層として学習する必要がある。  
（例えば、文章中の冠詞は同紙に比べて重要度が低いなど。 ）

### 確認テスト
- RNN：時系列データを扱うのに適したNN  
- word2vec:単語の分散表現ベクトルを得る手法
- seq2seq：１つの時系列データから別の時系列データを得るNN
- Attention Machinism：時系列データの中身の関連性に重みをつける手法。
# 深層学習day4
## Section1 強化学習
### 強化学習とは
長期的に報酬を最大化できるように環境のなかで行動を選択できるエージェントを作ることを目標とする機械学習の一分野  
行動の結果として与えられる利益をもとに、行動を決定する原理を改善するメカニズム  
近年発達した理由は計算速度の進展と関数近似法とQ学習を組み合わせること。
### 強化学習の応用例
- 環境：会社の販売促進部
- エージェント：キャンペーンメールを送る顧客を決めるソフト
- 行動：顧客ごとに送信、非送信の二つ行動をとる
- 報酬：キャンペーンコストとキャンペーンで生み出される売り上げ
### 探索と利用のトレードオフ
強化学習では環境についての知識はないと仮定する。そのため、ベストの行動を探す(探索)と過去の経験を活かす(利用)がトレードオフとなる。
### 強化学習のイメージ
学習をするのは[方策](報酬がたくさんもらえるように)と[価値]　(もっともよい価値を与える。。)
### 強化学習の差分
教師あり・教師なしは情報の特徴を抽出し予測する。強化学習は、行動の指針を学習する。
### 行動価値関数
価値関数には2つある  
- 状態価値関数：ある状態の価値に注目。エージェントの状態は関係ない。
- 行動価値関数：状態と価値を組み合わせた価値に注目
### 方策関数
ある状態でどのような行動を採るのかの確率を与える関数。行動価値関数が最大となるように決定する。
### 方策勾配法
方策をモデル化して最適化する手法。NNのW(重みに当たるものを学習) Θ_(t+1) = Θ_t + e * ∇J(Θ) 報酬が大きくなるようにしたいので+  
Jとは方策の良さ（期待報酬）を返す（NNの誤差関数）。これは定義を行う。定義方法は下記  
- 平均報酬
- 割引報酬和
## Section2 AlphaGo
2つの畳み込みニューラルネットワークからできている。AlphaGo LeeとAlphaGo zeroがある。
### AlphaGo Leeについて
#### PolicyNet（状態価値関数）
- - 盤面特徴入力は19×19 48チャンネル
畳み込みで中間層の活性化関数はReLU関数。出力層の活性化関数はSoftMax関数(二次元盤面の確率を出す。)
##### PolicyNetの学習
- 現状のPolicyNet VS PolicyPoolからランダムに選択したPolicyNetで対局を行う。PlicyNetとは強化学習の過程を500イテレーションごとに記録し保存したもの
- これにより過学習を防ぐことができる。mini batch size 128で1万回実施
#### ValueNet（行動価値関数）
- - 盤面特徴入力は19×19 49チャンネル。PolicyNetより手番を考慮するので1チャンネル増える。
畳み込みで中間層の活性化関数はReLU関数。全結合は2回かませて、出力層の活性化関数はTanH関数(勝ち負けの-1から1の1次元データ)
##### ValueNetの学習
- PolicyNetを使用して対局シュミレーションした結果の勝敗を教師として学習。
1. 教師あり学習で作成したPolicyNet(SL PolicyNet)でN手まで打つ
2. N+1手目をランダムに選択し、その手で進めた局面をS(N+1)とする。
3. S(N+1)から強化学習で作成したPolicyNet(RL PolicyNet)で終局まで打ち、その勝敗報酬をRとする。ここでPolicyNetを別とするのは過学習を防ぐため。
4. S(N+1)とRを教師データ対として、平均二乗誤差を損失関数として回帰問題として学習した
mini batch size 32で5000万回学習する。
#### RollOutPolicy(NNではなく線形の方策関数)
探索中に高速に着手確率を出すために使用する。強化学習のPolicyNetの1000倍のスピード(3マイクロ秒)
#### #PolicyNetの教師あり学習
人間の対局を教師あり学習として利用する。人間の着手手を1で残り0として盤面に配置する分類問題とする。
#### モンテカルロ木探索
詳細はまとめる。
### AlphaGo Zero
#### AlphaGo Leeとの違い
1. 強化学習のみで作成
2. 石の配置のみで学習。ヒューリスティック要素(入力のチャンネル数の着手後の呼吸点の数など人間が必要と思う要素)を排除
3. PlicyNetとValueNetを１つのネットワークに統合
4. Residual Netの導入
5. モンテカルロ木探索からRollOutシミュレーションを排除
#### AlphaGo ZeroのPolicyValueNet
方策関数と行動価値関数の出力を2つまとめて出力する。  
畳み込みをしてバッチ正則化→ReLU関数→ResidualBlockの後に2またの出力となる。各々の処理はAlpha Go Leeと同じ
#### ResidualNetwork
ネットワークにショートカット構造を用いて勾配の諸々の問題に対応する。
- 畳み込み→バッチ正則化→ReLU関数→畳み込み→バッチ正則化→Add→ReLU関数が1ブロック。Alpha Go Zeroでは39層ある。
- Batch Normalize(バッチの正規化)：miniBatch内で出力を平均0分散1に正規化する。
ショートカットにより、使用しない層が表現できる。そのため、いろんなネットワークを通る出力が得られる。
#### Alpha Go Zeroの工夫
- Bottleneck：次元削除と次元復元の層を増やして、計算量を変えずにNNの層を増やした。
- PreActivation：ResidualBlockの並びをバッチ正則化→ReLU関数→畳み込み→バッチ正則化→ReLU関数→畳み込み→Addとして性能が上昇
- WideResNet：畳み込み層のフィルター数をk倍にしたResNet。浅い層数でも深い層数のものと同等以上の精度を得られる。またGPUをより効率的に使用可能。
- PyramidNet：各層でFilter数を増やす。WideResNetで幅が広がった後の層の負荷上昇による精度低下への対策。
## Section3 軽量化・高速化技術
### モデル並列
モデルを細かいブロックに分けてワーカにそれぞれ学習させる。大きなモデルほど効果が大きい
※誤差の修正はどうするのだろうか。→最終的に出力内容を１か所に集約する。そのためネットワークを介さない１台のマシンで行うことが多い。
### データ並列
親モデルを各ワーカーに子モデルとしてコピー。そしてデータを分割し、各ワーカごとに計算させる。
#### 同期型
各ワーカの計算が終わったあと、全ワーカの勾配の平均を計算し、親モデルのパラメータを更新する。  
更新した親モデルをまた子モデルに配布する。  
精度は非同期型より高い。データセンターなどで使用
#### 非同期型
学習が済んだ子ワーカがモデルをパラメータサーバへプッシュする。新しいワーカはパラメータサーバからポップして学習する。  
スピードが同期型より高い。全世界のスマホで学習する際などに使用。
### GPU
簡単な並列処理が得意。そのため行列演算中心の深層学習と相性が良い。  
最近使われているのはCUDA
### 量子化
64bitのパラメータをわざと32bitに制度を落として、メモリと演算処理の削減を行う。  
bit数の拡張は、指数部と基数部を同じ割合で拡張するわけではない。また割り当て数を変えることも可能である。  
- 単精度:32bit 倍精度:64bit  
機械学習においては、半精度(16bit)多少精度が落ちても計算速度が大事

### 蒸留
規模の大きいモデル(レイヤーが深い)から軽量のモデル(レイヤーが浅い)を作る。  
教師モデルの重みを固定し、教師モデルと生徒モデルとの誤差の和を計算(教師モデルは学習済みなので誤差は非常に小さい)し、生徒モデルの重みを更新していく。
- 教師モデル：予測精度の高い、複雑なモデルやアンサンブルされたモデル
- 生徒モデル：教師モデルをもとに作成された軽量なモデル。

### プーリング
パラメータが大量にあるが、すべてのパラメータが結果に寄与していない。そのため不要なパラメータを削除する。  
閾値が特定の値より小さい重みを削除する。その結果最終結果に寄与しない重みも削除する。  
効果は想像以上に小さい。全体の94%のパラメータを削除しても、精度は90%程度となる！

## Section4 Transformer
ニューラル機械翻訳の弱点は長さに弱い。固定長ベクトルに圧縮するため
### Attentino(注意機構)
query(検索クエリ)に一致するkeyを探し、valueを取り出す。辞書オブジェクト機能を持つ  
文鳥が長くなっても翻訳精度が落ちない。 2種類ある
- Source Target Attention:情報とソースが分かれている。
- Self-Attentino：どの情報に着目するかを入力のみで決定する。CNNとよく似ているが、ウインドウサイズが文のサイズのコンボリューション。
### Transformer
RNNを用いずに同精度のものをAttentionのみで実現。  
1. RNNを用いないため、単語の位置情報を付加
2. Self-Attentionをかける。(Dot Product Attention)
3. 単語の位置ごとに独立処理する全結合
4. 未来の単語を見ないようマスク
### Position-Wise Feed-Forward Networks
普通に全結合を行うと、単語の位置情報を破壊するため、破壊しないように順伝搬を行う。

### Scaled dot product attention
QとKのドット積をとってきたあと、Mask(パッドなどの無視していい項に対して用いる)してSoftMAXとVの積をとる

### Multi-Head Attention
8個のScaled Dot-Product Attentionの出力を合わせて、それぞれのヘッドが異なる種類の情報を収集

## Section5 物体検知・セグメンテーション
### 物体認識タスク
タスクと出力内容の関係は下記。いままでの分類は画像の有無のみ、それ以降では物体位置および個々に興味を持つ。  
- 分類(Classification)：画像に対してクラスラベル
- 物体検知(Object Detection)：Bounding Box(bbox/BB)
- 意味領域分割(Semantic Segmentation)：各ピクセルに対し単一のクラスラベル（背景と物体を区別）
- 個体領域分割(Instance Segmentation)：各ピクセルに対し単一のクラスラベル（背景と物体各々を区別）
### 代表的データセット
| データセット名 | クラス | Train-Val | Box/画像(１枚当たりの物体数) | ラベル |
| --- | --- | --- | --- | --- |
| VOC12 | 20 | 11,540 | 2.4 | 物体個々 |
| ILSVRC17 | 200 | 476,668 | 1.1 |
| MS COCO18 | 80 | 123,287 | 7.3 | 物体個々 |
| OICOD18 | 500 | 1,743,042 | 7.0 | 物体個々 |
Box/画像(１枚当たりの物体数)が小さいとアイコン的で日常感とはかけ離れやすい
### 分類問題における評価指標の復習
| 真値\予測 | Positive | Negative |
| Positive | TruePositive(TP) | False Negative(FN) |
| Negative | False Positive(FP) | True Negative(TP) |
- Precision(予測がPositiveに対して、真値がPositiveなものの割合。適合率) = TP / (TP + FP)
- Recall(真値がPositiveに対して、予測がPositiveなものの割合。再現率) = TP / (TP + FN)
- confidenceの閾値(Threchold)を変化させるとPredictionも変化する。
- 後述するIoUについても閾値を準備する。
- 物体検知においてThresholdにより出力のサイズが変わってくる。(Confusion Matrixのサイズが変わる)
- IoU(Intersection over Union)=(Area of Overlap) / (Area of Union)　物体位置と物体予測位置の和集合における物体位置と物体予測位置の共通部分の比率
-- Confusion Matrixによる表現　IoU = TP / (TP + FP + FN)　Jaccard係数ともいう
- AP(Average Precision) PR曲線とR軸で囲まれた面積。クラスラベルごとに計算
- mAP：すべてのクラスにおけるAPの平均値
- PR曲線:PredictをRecallの関数として記述。PredictもRecallもconfidenceの関数として捉える。
- mAP_(coco):IoUの閾値を0.5から0.95まで0.05刻みでAPを計算。それによりmAPの算術平均を計算したもの
### 物体検知のフレームワーク
#### 2段階検出器
- RCNN SPPNet FPN MaskRCNNなど
- 候補領域とクラス推定を別々に行う。位置を切り出して分類器に取り込む
- メリット：精度が高い
- デメリット：計算量が多く、推論が遅い
#### 1段階検出器
- DetectorNet YOLO SSD など
- 候補領域とクラス推定を同時に行う。
- メリット：計算量が小さく推論が早い
- デメリット：精度が低い
### SSDの概略
1. Default Boxを用意
2. Default BOXを変形して、Predicted BBを得る
3. そのBBにconfidenceを添える
#### SSDのネットワークアーキテクチャ
- VGG16は畳み込み層13層、全結合層3層のアーキテクチャが基となっている。
- SSDでは全結合層3層のうち2層を畳み込み層に置換、最後の1層は削除
- SSDの特徴はマルチスケール特徴マップ
- - VGG10層目の畳み込み層、先ほど置き換えた畳み込み層、その先の畳み込み層をまとめて受け取っている
- 特徴マップの1つの特徴量に対して1つのDefaultBoxの出力は、クラス数とデフォルトボックスのオフセット(修正)項。内容は中心及び長方形サイズ
- 上記のオフセットは必ずしも出力だけ平行移動しているとは限らない
- 特徴マップの1つの特徴量に対してk個のDefaultBoxの出力は、1つのDefaultBoxの出力をk倍する。
- m×nの特徴マップでの出力は上記にmnをかける。
- 特徴マップのサイズが検出物体のサイズが決まる。特徴マップサイズは解像度。
#### 多数のDefaultBoxが存在することの問題
##### Non-Maximum Suppression
1つの特徴量に対して、多くのBBOXが存在する。(冗長化)  
IoUの最も大きいもののみを残すことで対処
##### Hard Negative Mining
背景クラスを検出しすぎる。(不均衡)  
Nagative(背景)の出力をPositiveの3倍までなどの制限をつける
#### 物体検出の損失関数
confidenceに対する損失に加えて、検出位置に対する損失を含める必要がある。
### Semantic Segmentation
#### 肝
小さくなった解像度を上げるところ。Up-samplingが必要。  
VGG16の全結合層を畳み込み層とする。
#### なぜプーリング層が必要なのか
正しく認識するためには受容野に大きさが必要であるから。畳み込み層を深くしても解消できるが計算量増加、メモリ不足に陥る
#### Deconbolution/Transposed Conbolution（逆畳み込み）
1. 特徴マップのpixel間隔をstrideだけ空ける
2. 特徴マップのまわりに(kernel size -1)- padding だけ余白を作る
3. 畳み込み演算を行う
- もちろん逆演算ではない。
#### 輪郭情報の補完
プーリングによって、ローカル情報(輪郭)が失われていく。そのため、最終的なプーリング結果を逆畳み込みしても輪郭が曖昧なままとなる。  
これを避けるため、プーリングを逆畳み込みした情報に、低レイヤーのプーリング結果を要素ごとに足し合わせて逆畳み込みを行い、情報を補完していく。
#### Unpooling
プーリングの位置情報を保持する。（Max poolingではどこが最大値があったのかという情報を保存する。）
#### Dilated Convolution
畳み込みの段階で受容野を広げる工夫の一つ。  
層が離れるにつれて、畳み込みのリンクを離していく→る受容野広い


## 応用技術
### MobileNet
- 画像認識ネットワーク
- 通常の畳み込み計算量(パディング1,ストライド1の場合、計算量は(出力のサイズ)×(カーネルマップ)×(フィルターサイズ))をDepthwise ConvolutionとPointwise Convolutionで軽量化したもの。メモリ量も14M程度まで削減できる。
#### Depthwise Convolution
- フィルタ数が1
- カーネルの枚数が1(入力をまとめて畳み込みをしない)
- 出力チャンネルは入力と同じ
- 計算量は(出力マップ)×(カーネルサイズ)
#### Pointwise Convolution
- カーネルサイズを1 × 1で畳み込み
- 任意のチャンネルを出力する。
- 計算量は(カーネルチャンネル)×(フィルター数)×(出力マップ)
### Dense Net
- 画像認識モデル。
- Denseブロックを畳み込み後に追加する。
#### DenseBlock
前のレイヤーを足し合わせて出力していく
Batch正規化　Relu関数　畳み込み3×3
出力チャンネルが畳み込みのチャンネル分増えていく。このチャンネルは成長率と呼ばれるハイパーパラメータ
#### Transition Layer
畳み込みとプーリングの処理を行ってチャンネル数をもとに戻す。
#### ResNetとの違い
- DenseNetでは前方からの出力をすべて後方へ伝える。ResNetでは前1層の入力のみ後方へ伝える。
### Batch Norm
ミニバッチに含まれるサンプルの同一チャンネルが同一正規分布に従うように正規化。  
このバッチサイズが小さいと学習結果が収束しない。このバッチサイズはデバイス性能に依存する。  
#### Layer Norm
1つの画像に対してpixelsが同一分布に従うように正規化
#### Instance Norm
1つの画像の同一Channelのみ分布に従うように正規化
### WaveNet
- 音声生成モデル。畳み込みで処理ができる。通常は近接したリンクをつける。WavenetはDilated Convolution

### 確認問題 Deconvolution(逆畳み込み)
情報量が増える畳み込み。画像の解像度を上げるために使う
