# 機械学習
## 線形回帰モデル
### まとめ
- 回帰問題を解くための教師あり学習
- 与えられたデータを一次式で予測する。  
基本的には説明変数がn次元、目的変数が１次元する。  
出力を多次元にすることも可能  
誤差項は偶発誤差だけでなく、隠れた説明変数の項が乗っていることがある。
目的変数に対して、目的変数が少ないとき。
基本的に目的変数の次元より、重みの次元は低い
- 誤差(最小二乗誤差)を最小とするのが目的
- - ただし外れ値に弱い。影響されやすい



バクニックの原理
みつどひすいてい
データ分割　汎化性能を計測するために必要。数学的にも計算できる
Huber損失　Tukey損失
射影行列
一般化逆行列

## 非線形回帰モデル
### まとめ
## ロジスティック回帰モデル
### まとめ
## 主成分分析
### まとめ
## アルゴリズム
### まとめ
## SVM
### まとめ


